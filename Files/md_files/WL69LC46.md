# <h1>Outsourcing cyber power: Why proxy conflict in cyberspace may no longer pay</h1>

## Cyber Proxies: What We Know

### States outsource proxy activity to obscure involvement and gain advantages without repercussions.

> “FORMER president Dwight D. Eisenhower once remarked that proxy conflict is “the cheapest insurance in the world” [1]. But why would a state outsource something it can do for itself? In the classical framework, states outsource to non-state proxies in order to obscure their involvement [2–4]. By refraining from direct action, all the while tacitly permitting or actively supporting proxy activity, host governments are able to enjoy foreign policy or military gains without admitting to culpability. Host states that do this successfully elude the usual risks from using force against a capable adversary, ranging from sanctions and reputational damage [5] to armed escalation [1, 6, 7]. This logic is widely assumed to hold in cyberspace, as well [8, 9]. And yet, if cyber proxies offer such clear advantages, it is puzzling why this strategy has not universally proliferated, especially among states that are host to highly capable and ideologically aligned hacker collectives.” (Canfil, 2020, p. 1)

## Cyber Proxies: What We Know

### Plausible deniability of proxies in cyberspace may be diminishing due to increasing victim responses.

> “How have global patterns in the use of cyber proxies changed, if at all? This paper supposes that proxy conflict in cyberspace may no longer pay – at least not for the reason scholars ordinarily assume, plausible deniability. Despite its status as a widely assumed causal mechanism, deniability for proxies may not very plausible, after all. Victims set the evidentiary threshold for themselves. In fact, victims are free to make whatever allegations they like. Proxies sometimes even out themselves to claim credit [10], undermining any remaining veneer of secrecy. Nor in many cases do alleged sponsors even bother to deny victims’ accusations, for example because there is signaling value in implicating oneself [11]. Deniability is only plausible to the extent it discourages retaliatory action. If victims are increasingly willing to respond on the basis of imperfect attribution [12, 13], attackers cannot hope to gain much political cover by outsourcing to proxies. Without plausible deniability, proxies may lose their luster.” (Canfil, 2020, p. 1)

## Cyber Proxies: What We Know

### Technological developments challenge the credibility of plausible deniability in covert actions.

> “Scholars of cyber conflict would do well to take seriously this proposition. Writing on reasons for covert action in physical domains, Cormac and Aldrich [14] argue that “even in its supposed heyday, the concept [of plausible deniability] was deeply problematic. Changes in technology and the media, combined with the rise of special forces and private military companies, give it even less credibility today.” These include advances in attribution technology, attribution from the private sector, media coverage, and the proliferation of in-house government cyber capabilities. Similarly, Lin-Greenberg and Milonopoulos [15] and Vaynman [16] have argued that open-source surveillance and monitoring technologies make it difficult for governments to hide their illicit activities in any domain. It stands to reason that this logic would hold for cyberspace as well. For instance, private cyber analysis firms have proliferated in number, and face fewer political barriers than states in making independent attributions. As Cormac and Aldrich [14] explain, “we live in an era of implausible deniability.”” (Canfil, 2020, p. 2)

## Cyber Proxies: What We Know

### Formal modeling suggests that insourcing may be preferred over outsourcing in cyber operations.

> “In this paper, a formal model is used to generate hypotheses about why states might choose insourcing over outsourcing, even when proxies are both highly capable and perfectly committed to carrying out their orders. The model relaxes a standard assumption that deniability is solely a function of the sponsor’s level of investment, instead considering the target state’s willingness to cast blame even when evidence connecting the sponsor to its proxy is circumstantial. The minimization of principal-agent problems in the model is helpful an as extreme test of the theory that proxies might not pay for external reasons. The theoretical predictions are supported by new empirical data. Deniability is least plausible when there is clear evidence that a sponsoring state conducted an operation directly, insourcing to its own personnel. I find that public US reprisals are associated with more insourcing, as opposed to more outsourcing, in subsequent operations. These findings contribute to an emerging body of research that has questioned the logic of plausible deniability in covert action, including cyber conflict [10, 11, 14].” (Canfil, 2020, p. 2)

## Cyber Proxies: What We Know

### Insourcing is rising as states adapt to victims' willingness to retaliate and political dynamics.

> “The proposition that proxies may no longer pay is intended to be suggestive, not definitive. Despite the confirmatory evidence, the paper stops short of asserting that proxy conflict is in fact known to be declining. Instead, the argument serves to remind scholars to question their underlying assumptions about why states outsource, given that alternative explanations make predictions with observationally equivalent empirical implications. We can, however, measure and test the converse – insourcing. The findings show that insourcing is on the rise, especially in response to finger-pointing by powerful victims. Because victims are increasingly willing and able to blame, and because the obviousness of insourcing shatters any remaining plausible deniability, these findings suggest that outsourcing may not be as en vogue as is widely assumed for aggressors who desire political cover.” (Canfil, 2020, p. 3)

## Cyber Proxies: What We Know

### Proxies can still be effective in specific contexts despite the loss of political cover.

> “That is not to say that proxies never paid, or do not pay still under certain circumstances. To date, some 400,000 multinational hackers have reportedly volunteered to aid the besieged Ukrainian government against Russia in the ongoing 2022 war [17]. Ukrainian officials have openly welcomed their assistance. Ukraine’s Minister of Digital Transformation even tweeted an open invitation to join his “IT army” and to “fight on the cyber front” [18]. By doing so, of course, Ukraine cannot plausibly deny a relationship with its proxies. Nor would it presumably care to, given the state of war. Proxies may still sometimes pay, but if or when they do, it must be for reasons other than political cover.” (Canfil, 2020, p. 3)

## 1 Cyber Proxies: What We Know

### Non-state actors, driven by various motivations, have been significant in international cyber conflicts.

> “Whether driven by ideological zeal, nationalism, or money, non-state actors have long been a persistent phenomenon in international conflict, including cyber conflict.1 For instance, in 2001, Chinese hacktivists, encouraged by the state, targeted United States (US) government websites in retaliation for the EP-3 incident [24–27]. Taiwanese networks were also targeted during a period of growing cross-Strait tensions that same year [28]. Even the world’s most notorious cyber conflict “wake-up call” [29], the attack on Estonia in 2007, was putatively facilitated by a pro-Russian youth organization [24, 30]. Such observations undoubtedly contributed to predictions that cyberspace would profoundly level the playing field between nation states and non-state actors [31].” (Canfil, 2020, p. 3)

## 1 Cyber Proxies: What We Know

### States continue to play a crucial role by co-opting non-state hackers as cyber proxies.

> “But states have not disappeared as a central actor, even in cyberspace. States which are host to non-state hackers can often co-opt these actors in order to advance operational objectives [32]. As Akoto [33] explains, “[cyber] operations have proliferated ... [and] states are increasingly outsourcing them to non-state actors” – also known as “cyber proxies.”2 I use the term “sponsor” to refer to a sovereign power that relies on non-state actors to complete some operational cyber objective; to the non-state actor as that sponsor’s “proxy”; and to this relationship as “outsourcing,” as opposed to “insourcing”: centrally coordinated, direct action by the sponsor.” (Canfil, 2020, p. 4)

## 1 Cyber Proxies: What We Know

### The relationship between states and non-state actors varies, influencing levels of responsibility.

> “This of course describes a very general relationship. Scholars recognize a range of connections states might have with non-state actors. Healey [34] identifies up to ten types of arrangements, ranging from abeyance or disavowal at one extreme to command centralization at the other. Maurer [35] distills this into three core managerial strategies: delegating, funding, tacitly permitting.3 More recent work by Florian Egloff [32] refines this further. Such frameworks are useful and come with one unsurprising takeaway: the greater the level and intensity of state support, the greater the objective certainty that the state is formally responsible [36].” (Canfil, 2020, p. 4)

## 1 Cyber Proxies: What We Know

### Cyber proxies provide states with plausible deniability in cyber conflicts.

> “Detection and attribution in cyberspace are challenging, but not impossible. Because of this, it is widely believed that the use of a proxy bestows sponsoring states with an added layer of plausible deniability [8, 35, 37–42]. Cyber proxies by definition operate under a different command structure and may work physically apart from regular uniformed personnel. Even if a perpetrator can be tracked down, organizational separation between that perpetrator and the principal to whom she reports can make it difficult for victims to know the principal’s involvement. Plausible deniability helps distance sponsoring states from the risk of attribution.” (Canfil, 2020, p. 4)

## 1 Cyber Proxies: What We Know

### Victim states face challenges in prosecuting hackers, allowing states to use proxies with minimal risk.

> “Victim states may find it hard to exercise prosecutorial jurisdiction over individual hackers, especially where extradition agreements are lacking, so law enforcement cannot lean on the culprits to implicate their state sponsors [43]. If true, then it stands to reason that states can use their proxies to secure operational objectives at low cost and low risk of attribution.” (Canfil, 2020, p. 5)

## 1 Cyber Proxies: What We Know

### Patriotic hackers align with state goals, reducing monetary dependency and enhancing plausible deniability.

> “Some non-state hackers cooperate with states for ideological reasons, not just money or glory. So-called “patriotic hackers” first appeared as early as 1998 [44]. Among cyber proxies, patriotic hackers should offer their sponsors the best of both worlds. Would-be state sponsors face a classic principal-agent dilemma: by empowering non-state hackers, the state reaps the benefits of an operation while minimizing its exposure if the operation is traced to the perpetrators. But non-state hackers may have their own agenda. States that turn a blind eye run the risk of operational deviations, and states that provision their proxies with resources and material support may face a “Promethean dilemma” if those proxies later use their newfound capabilities against their sponsors [8]. Because patriotic hackers support state objectives for ideological reasons, the sponsoring state need not rely on side payments [45] to keep them in line. Without a money trail leading back to the sponsoring state, the usual principal-agent risks are minimized: the state can be assured of its proxy’s fidelity, and plausible deniability is strengthened.” (Canfil, 2020, p. 5)

## 1 Cyber Proxies: What We Know

### Scholars suspect a widespread reliance on cyber proxies, despite U.S. caution against such practices.

> “This logic has led many scholars to assume that reliance on cyber proxies must be widespread. Russia [35, 46], China [25, 26], Iran [40], and North Korea [47] – all of which possess their own powerful cyber capabilities – are usually regarded as the most complicit. Standard accounts rarely note how the outsourcing model has been at various stages endorsed in countries like Japan, India, and Estonia [45, 48], and (allegedly) employed by several Western countries [38, 42, 49–51]. On the other hand, scholars acknowledge that proxies are not ubiquitous. The US has traditionally kept its non-state hacker community on a tight leash by discouraging operational participation [35, 46].4 Between 9/11 and the start of the Iraq War, for example, when US nationalism soared, the US National Infrastructure Protection Center (NIPC) posted a notice explicitly warning overzealous Americans not to hack Iraqi targets [53]. On the surface this might seem surprising, since the US shown little reluctance to engage in proxy warfare in other domains.” (Canfil, 2020, p. 6)

## 1 Cyber Proxies: What We Know

### Data limitations hinder the understanding of the prevalence and nature of cyber proxies.

> “So just how prevalent are cyber proxies? How can we know? When making inferences about global patterns, researchers must rely on large-n datasets. The data are based on public reports and involve multiple hurdles – detection by the victim, admission and disclosure, sufficient evidence, media attention, and attribution. As Akoto [33] explains, these data limitations have “crippled efforts to study ... cyber proxies.” Only in cases where the target detects an intrusion, admits to it, and alleges the involvement of a foreign state sponsor will that case will show up in open-source cyber conflict datasets.” (Canfil, 2020, p. 6)

## 1 Cyber Proxies: What We Know

### Victim perceptions play a crucial role in recognizing and reporting proxy relationships in cyber incidents.

> “The third point – allegations – is key. The relationship between a sponsor and its proxies must be inferred by the target or other observers. Especially bold (or frustrated) victim states might overstate their level of confidence about who the culprit is. Cautious victims might decline to make allegations with any certainty at all. What this means is that the criteria for inclusion in the universe of observed cases is a function of victim transparency and observer beliefs.” (Canfil, 2020, p. 6)

## 1 Cyber Proxies: What We Know

### Research on cyber proxies is complicated by data reflecting only failed plausible denials.

> “For researchers interested in studying cyber proxies, this raises a troubling prospect: the dominant explanation for why states outsource to proxies is plausible deniability, but scholars can only observe cases in which denials were not considered plausible enough to prevent attribution. Scholars of cyber conflict have done excellent work to circumvent data problems in other areas [54–56], but for this reason the study of cyber proxies faces a special set of challenges.” (Canfil, 2020, p. 6)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Outsourcing may lead to less recorded cases due to harder attribution.

> “The crux of the problem is thus. Assume outsourcing bestows plausible deniability by making attribution harder, and that plausible deniability is something states desire. If outsourcing is on the rise as is commonly assumed, it follows that we should actually record fewer cases in the data over time, not more, because attributions will seem incredible. On the other hand, if outsourcing

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### The ambiguity of outsourcing data complicates understanding state interests.

> Praesentium voluptatum deleniti atque corrupti, quos dolores et quas molestias excepturi sint, qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum, quia dolor sit, amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur.doesn’t convey much plausible deniability, or if states have more interest in operational reliability than plausible deniability, we would also record fewer cases. This would be for precisely the opposite reason: because outsourcing is no longer an unattractive strategy. There is no direct way to adjudicate between these processes with the available open-source data.” (Canfil, 2020, p. 7)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Different datasets do not differentiate between insourced and outsourced operations.

> “To illustrate this problem of observational equivalence, I compare observations from three datasets: Valeriano [56]’s Dyadic Cyber Incident and Dispute Dataset 1.5 (“VJM”);5 the Council on Foreign Relations’ Cyber Operations Tracker (“CFR”) [57];6 and Akoto [33]’s dataset on cyber proxy onset.7 CFR [57] and VJM [56] track incidents in which state involvement was suspected, but neither differentiates between insourced and outsourced operations.8” (Canfil, 2020, p. 7)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Trends from multiple datasets suggest weaker claims of widespread proxy use.

> “Figure 1: Comparisons of trends over time from three datasets [33, 57, 58]. The leftmost column plots the full set of observations by sponsoring faction. The rightmost column plots correlates of proxy support. Loess curves (95 percent confidence intervals) plot trends by faction. Factions are organized around US allies (blue), adversaries (red), and other states (gray). After subsetting on likely proxy activity (right), claims that proxies are widespread seem much weaker, especially in the last decade. Figure 1 compares observations from all three datasets. The Y -axis in the first two rows depict the number of reported cyber incidents in the CFR/VJM data. The the third row maps the total number of proxy relationships in the Akoto dataset over time. Loess curves (95 percent confidence intervals) measure the change in Y values over time, sorted by country faction.12 Next, contrast the left and right columns for each row. Left columns in the top two rows plot the full universe of reported operations (CFR; VJM) and total number of proxy relationships in the international system (Akoto). Conversely, the right columns subset that data on the correlates of proxy activity (i.e. operations other than espionage and APTs). Meanwhile, on the third row, the right column plots the number of newly added proxies.” (Canfil, 2020, p. 8)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Recent data indicates that espionage activities are primarily driven by Russian and Chinese efforts.

> “We can see that although incidents have become more frequent overall according to CFR (top row), this activity is driven almost entirely by Russian and Chinese espionage. Likewise, the VJM data depicts an apparent decrease in activity other than APTs, especially after 2013. Differences in the Akoto data, which explicitly tracks proxy activity, are most striking. At first glance, the left column of the third row would seem to indicate that US adversaries have drastically increased the number of groups to whom they outsource. However, keep in mind this is strictly a cumulative measure, and does not track when groups disband or are abandoned or absorbed by their sponsors. The right column tracks the onset of new relationships. It becomes apparent that the rate of outsourcing flags after 2010.” (Canfil, 2020, p. 9)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Outsourcing trends could indicate changes in common practices over time.

> “These trends could tell one of two mutually exclusive stories. At first glance, it might seem that outsourcing is actually less common now than is usually assumed. Alternatively, Akoto [33] explains that in order for the onset of a proxy relationship to appear in the dataset, “there must be strong evidence that a group is acting on behalf of, at the behest of or with the active support of the government” (emphasis mine). Akoto [33] continues: “It is insufficient for a group to be considered a proxy simply because it is ideologically aligned with the government, shares a common enemy or does not oppose the government ... [as long as the group is] somewhat independent of the state.”13 Data collection is scoped on proxies which are already known to work for the state. Innclusion in the dataset is therefore inversely related the plausibility of a sponsor’s deniability.” (Canfil, 2020, p. 9)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Available data may exclude many proxies that provide plausible deniability.

> “What this means is that the large-n information we do have consists of cases in which denials were implausible. If proxies really do convey plausible deniability, then they are less likely than insourced operations to appear in datasets that treat nation states as the unit of analysis. Assuming plausible deniability is in fact the main reason states outsource, the data systematically exclude exactly the types of proxies to whom states have any interest in delegating.” (Canfil, 2020, p. 9)

## 1 Cyber Proxies: What We Know:1.1 Observational Equivalence in Existing Data

### Current data cannot clearly support or refute the prevalence of outsourcing.

> “Direct measurements of outsourcing in available data cannot distinguish between these competing accounts. On the one hand, outsourcing could be more common because sponsoring states are outsourcing to proxies who are more deniable. If states can in fact use proxies to achieve plausible deniability, the dearth of empirical evidence to attest to the fact is only natural, because academics would be among the last to become aware of the true relationship. On the other hand, outsourcing could really be less common now because sponsoring states are learning that their deniability isn’t plausible as they had hoped. After all, if academics can code your relationship, it is unlikely to fool a sophisticated adversary.” (Canfil, 2020, p. 10)

## 2.The Illogic of Plausible Deniability

### Attribution challenges in cyber conflicts are diminishing.

> “It has long been assumed that proxy conflict is attractive precisely because it offers state sponsors plausible deniability. This section theorizes about why that might no longer be true. In the early days of cyber conflict, attack attribution [59, 60] was widely regarded as its “most difficult problem” [61]. The barriers to attribution prevented victims from identifying and holding aggressor accountable. It more recent years, however, the attribution problem has come to be seen as less problematic [62, 63]. Attribution may be onerous and complicated, but it is technically possible [12, 13, 64]. Victims typically work to piece together an idea of the likeliest culprits based on indicators of compromise (IOCs), an accumulation of technical clues and circumstantial patterns [65].” (Canfil, 2020, p. 10)

## 2.The Illogic of Plausible Deniability

### Identifying attackers and their sponsors remains complex and legally challenging.

> “Even if victims are able to trace the source of an attack, knowing who the people behind the terminal are and who they work for is a far more challenging set of questions. First, private sector targets are often the gatekeepers of forensic evidence and may have countervailing incentives not to disclose [33]. States are often sensitive about divulging how they know what they know [66]. Assuming a victim state is willing to broadcast the evidence it collected, the burden of proof to implicate a sponsoring state is prohibitively high as a matter of international law. Though the law is not completely settled, jurists usually interpret it to mean that only sponsors who take on a direct command role can be held responsible for the actions of their proxies [36, 67].14” (Canfil, 2020, p. 11)

## 2.The Illogic of Plausible Deniability

### The appeal of cyber proxies is questioned amidst varying accountability frameworks.

> “These barriers are what make outsourcing so attractive, according to conventional wisdom [35]. But assuming cyber proxies convey plausible deniability for their sponsors, and sponsors find plausible deniability desirable, why is reliance on proxies not universal [33, 68]? In the US case, scholars often point to philosophical disagreements between Washington and Silicon Valley [e.g. 35]. Others have argued that authoritarian countries and democracies face disparate accountability barriers [33, 69]. A debate exists as to the real prevalence of proxies among authoritarian countries, as well [see 70]. Russia and China have since 2016 exhibited an increased interest in more tightly-controlled cyber operations. Both countries have adopted stronger and more centralized domestic cyber institutions [55], and in 2016 Segal [71] described plans to adopt a model reminiscent of US Cyber Command.” (Canfil, 2020, p. 11)

## 2.The Illogic of Plausible Deniability

### China has shifted from tacit support for cyber proxies to stricter control over cyber operations.

> “From 1994-2003, the Chinese government was suspected of tacitly permitting its proxies to attack foreign targets, and from 2003-2013 the state appeared to provide active support [28]. Despite rising online nationalism in China [72] and an army of cyber privateers that once purportedly numbered almost 200,000 [24], however, Beijing has since tightened its enforcement of internal cybersecurity laws. For example, Hang [73] catalogues eleven patriotic hacking episodes alleged to have been sponsored by China. Yet all but four occurred prior to 2001 and none after 2010. The leader of the Honker’s Union (中 国 红 客), which began as a Chinese patriotic hacker collective in the 2000s [see 74], warned his colleagues in 2011 that they “probably won’t” be permitted by the government to continue attacking foreign targets [75]. Since then, the Chinese government has relied more on specialized units at the Ministry of State Security [35, 71]. Attacks originating from that country reveal a more direct government hand [76].15 If proxies pay for the reasons we usually suspect, then this behavior is puzzling.” (Canfil, 2020, p. 12)

## 2.The Illogic of Plausible Deniability

### Victims increasingly attribute cyber attacks despite attribution challenges.

> “Rarely do cyber attacks leave smoking gun evidence about who was involved. Attribution is already hard, so plausible deniability should make for an additional hurdle. Yet victims can and do increasingly point the finger, even when attributions are imperfect [12, 13, 77, 78]. Cui bono (“who benefits?”) tests are themselves commonly regarded by decisionmakers as a kind of evidence. A victim may still suspect its adversaries of being behind an attack perpetrated by ostensibly non-state hackers. In such a case, the target state might privately or publicly respond through an act of retorsion, naming and shaming, sanctioning, or launching a proportional cyber response. Since 2014, the US and other powerful states have even begun to publicly attribute cyber incidents to specific individuals that they say were working on behalf of sponsoring governments. Sometimes these are based on extensive evidence. In other cases, detailed evidence is not provided.” (Canfil, 2020, p. 12)

## 2.The Illogic of Plausible Deniability

### The US government is intensifying its indictments of foreign cyber attackers.

> “In particular, the propensity of US Department of Justice to indict foreign hackers has increased in recent years, despite the difficulty of trying these defendants in US courts [43]. In 2014, the US Department of Justice (DOJ) famously indicted five Chinese People’s Liberation Army (PLA) officers for allegedly “hacking under the shadow of their country’s flag” in order to escape punishment [79]. Though an indictment under US criminal law signaled the government’s view that the suspects were individuals, the attribution to China was explicit. Comparing this 2014 indictment to the Equifax hack three years later, observe that DOJ named 30 accomplices [80] a sixfold uptick in the number of implicated individuals. The US government has continued to aggressively indict foreign hackers it considers to be nation-state proxies [eg. 81–85]. Speaking on behalf of the US government, former US Acting Deputy Attorney General John Carlin argued that proxies “are not immune from the law” and that the US “will hold state sponsored cyber thieves accountable” [79].” (Canfil, 2020, p. 12)

## 2.The Illogic of Plausible Deniability

### Enhanced cooperation among US agencies improves attribution capabilities.

> “It is worth examining how, practically speaking, the US DOJ is able to piece together an argument that cyber incidents are indeed “state-sponsored.”16 In a separate piece, Carlin [43] explains that the Criminal and National Security Divisions at DOJ "increasingly find [them]selves working cases jointly (or at least more actively supporting each other’s cases)," including by embedding special agents from Counterintelligence with the FBI’s Cyber Division. Enabled by post-9/11 changes to the structure of the intelligence community, these interagency and public-private collaborations – in Carlin’s own words – were motivated by the early cyber proxy landscape.17” (Canfil, 2020, p. 13)

## 2.The Illogic of Plausible Deniability

### Political aspects of attribution influence the response to cyber incidents.

> “This level of cooperation gives the government specially enhanced attribution capabilities. Carlin [43] describes the idea that the US has an attribution problem as “antiquated.” As former National Security Agency General Counsel Stewart Baker stated in 2015, “we can [now] know who our attackers are" [Congressional testimony, quoted in 43]. Victims may be more willing to attribute their attackers when an attack has large-scale and high-profile consequences, even if evidence is weak [13].” (Canfil, 2020, p. 13)

## 2.The Illogic of Plausible Deniability

### The DOJ's desire for state sponsorship attribution pressures investigations.

> “Especially for these types of cases, DOJ has a strong motivation to attribute a state sponsor. DOJ depends on court-issued warrants for its investigatory powers, and warrants are often obtained by naming a nation state. As Carlin [43] admits, nation state attribution is actually crucial in the Foreign Intelligence Surveillance Act (FISA) process: "the government must demonstrate, among other things, that the ’target ... is a foreign power or an agent of a foreign power’" if it hopes to obtain a FISA warrant. Presumably this creates pressure for DOJ to implicate uncooperative states who are host to cyber attackers, whether or not the state-proxy evidence is rock solid.” (Canfil, 2020, p. 13)

## 2.The Illogic of Plausible Deniability

### Indictments require some evidence, but not a level of proof that can be tested in court.

> “Indictments still require a degree of legally admissible evidence, even if the governments understands the ability to actually convict on this evidentiary basis will never be tested. But even short of formal indictments, the US began acting on its suspicions when it initiated its new operating concept, persistent engagement [85–87]. To my knowledge, there is no institutional requirement to show that the target of a “hunt forward” operation has legally demonstrable links to a host government. Would-be sponsors must certainly be aware that outsourcing does not automatically bestow political impunity. At best, outsourcing might only convey international legal protection in an environment where international law is already permissive; that is, for operations below the level of an armed attack [see 88]. Where once victim states like the US exhibited “restrained responses” [89], they now seem more willing to punish sponsors for the activities of their proxies.18” (Canfil, 2020, p. 14)

## 2.The Illogic of Plausible Deniability

### Victims may retaliate based on high suspicion rather than conclusive evidence.

> “After all, why wouldn’t victims overplay rather than underplay their hand? If international relations were a courtroom, then proxies might not implicate their sponsors beyond a reasonable doubt. But pointing the finger in international relations is far more political. It is the victim that decides the burden of proof. Political attribution bridges the gap between technical facts and suspicions, “reducing uncertainty about who is behind an intrusion” and “creating cybersecurity ‘truths”’ for victims with the means to retaliate [90]. States may be learning that they can expect to be blamed even when victims cannot establish a rock solid evidentiary link. Even refusal to cooperate in stopping attacks emanating from within one’s borders might be construed as tacit support. If so, advances in the technology of attribution, coupled with victim states’ newfound willingness to make allegations on the basis of strong suspicion rather than hard evidence, may mean that deniability offers fewer advantages than it once did.” (Canfil, 2020, p. 14)

## 2.The Illogic of Plausible Deniability

### Merely raising suspicions can undermine plausible deniability.

> “Raising suspicions may be enough to incur a victim’s ire. As long as perpetrators can be linked with some confidence to possible sponsor – even if that confidence is not absolute – the plausible deniability assumption may not hold.” (Canfil, 2020, p. 14)

## 2.The Illogic of Plausible Deniability:2.1 A Model of Outsourcing

### Formal models are underutilized tools for analyzing cyber conflict and proxies.

> “How can we study this proposition? One way of challenging assumptions is to check whether one’s assumptions are sensitive to reconfiguration. Formal models are the appropriate technology for checking and comparing a theory’s internal validity this way. Following Baliga, Mesquita, and Wolitzky [12], Lindsay [13], and Axelrod and Iliev [91], I formally model an aspect of cyber conflict. Despite the use of formal models for studying proxy relationships in other domains, this technology has rarely been applied to questions of cyber conflict and to my knowledge has never yet been applied to cyber proxies. Formal models are not empirical tools per se, but they do allow researchers to understand how data-generating processes may work “under the hood” in cases where data are questionable or unavailable.” (Canfil, 2020, p. 15)

## 2.The Illogic of Plausible Deniability:2.1 A Model of Outsourcing

### Assumptions regarding cyber proxies revolve around plausible deniability and their widespread utility.

> “Every theory is based on core assumptions. The literature on cyber proxies has long assumed three points. First, cyber proxies offer plausible deniability. Second, sponsors desire plausible deniability, and therefore find proxies useful. Third, because of this, the use of proxies must be widespread. (As Section 3 will discuss in detail, absent large-n data, these assumptions have been difficult to challenge.) The third point has been demonstrated through anecdotes and case studies, but it has been difficult to measure changes in the global rate over time. Formal models can be used to illustrate how processes very different from the ones we assume can produce observationally equivalent, but possibly spurious, outcomes [92].” (Canfil, 2020, p. 15)

## 2.The Illogic of Plausible Deniability:2.1 A Model of Outsourcing

### The model differentiates between outsourcing and insourcing cyber operations based on investment levels.

> “In the model, a host government faces a choice between outsourcing (turning a blind eye or actively supporting non-state actors) versus insourcing (conducting cyber operations using its own, in-house capabilities). Evidence is a function of how much a sponsor invests in the units charged with carrying out the attack. The more is invested, the more obviously the sponsor is linked to the operation. However, a key difference in the model is to relax the dependence between victims’ beliefs and the level of investment. Under this framework, the sponsor’s deniability is a function of its involvement and the target state’s independent willingness to make accusations. This is a generalization of the conventional wisdom, since it does not assume that all victims have an identical standard for the burden of proof.” (Canfil, 2020, p. 15)

## 2.The Illogic of Plausible Deniability:2.1 A Model of Outsourcing

### Concerns about retaliation based on indirect evidence may deter sponsors from outsourcing despite proxy capabilities.

> “The model shows how a sponsor’s concern that victims will retaliate on the basis of imperfect or indirect evidence can be sufficient to discourage that sponsor from outsourcing. Note that this holds even when proxies are ideologically faithful and highly competent. In the real-world, outsourcing comes with all the downsides typically associated with a principal-agent relationship [8]. The model holds these widely established principal-agent problems constant at their ideal, setting them aside so that other mechanisms can be studied under controlled conditions. For this reason, the decision to outsource can be modeled as decision-theoretic. This permits a more specialized focus on plausible deniability’s role in decisions about whether to outsource.” (Canfil, 2020, p. 16)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### The host government determines the level of outsourcing for cyber operations.

> “A host government (G) oversees a pool of non-state hackers (H ). The government is interested in engaging in cyber operations, but must decide whether its offensive cyber operations should be, on balance, more centralized or outsourced. Define this decision as φ ∈ [0, 1], where φ > 0 is some positive degree of outsourcing. One can imagine that low levels of φ represent tacit permissiveness, higher levels represent encouragement, and the highest levels represent funding, support, and direction. Conversely, the government runs its own operations and discourages non-state activity at φ = 0, for instance by implementing and enforcing laws against hacking foreign targets. In the game, G’s campaign payoff aggregates an arbitrarily high number of operational payoffs given its chosen degree of command centralization. For ease, Table 1 contains a guide to notation.” (Canfil, 2020, p. 16)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### Investment levels significantly affect the government's return from cyber operations.

> “The government’s return on investment is given as u ̃x, where x is its aggregate level of investment. Investment determines how intrusive the attacks are, and therefore how much information or destructive opportunity they yield. Penetration capabilities also vary by the attacker’s level of sophistication, ψi . The probability of a successful campaign is ψi . I assume that individual operations are scalable, and thus the government obtains either full benefit u ̃x from a successful campaign (ψ = 1) or no benefit at all (1 − ψ).19” (Canfil, 2020, p. 16)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### The government faces principal-agent problems with non-state hackers.

> “Consistent with default explanations, G faces principal-agent problems vis-a-vis H . The degree of agent drift – a function of H ’s operational discipline and its ideological sympathy with government objectives – is written as θ. The government’s level of investment x, and thus its expected payoffs, are penalized increasing in θ. In other words, the less reliable the agent (θ ↑), the less useful its efforts.” (Canfil, 2020, p. 17)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### The centralization of cyber operations influences the government's plausible deniability.

> “Finally, G gains some plausible deniability depending on its centralization strategy. The extant literature assumes that plausible deniability is a function of the level of centralization, f (φ), and that the attacker faces penalties increasing in attack scale, x. This would be modeled as x × φ: the less centralized, the more deniability when scale is held constant.20 The legal standard for attribution, as stated previously, requires effective control over command and operations; simply permitting, encouraging, or even funding is not sufficient to trigger a target’s right to self-defense. Thus only centralized operations should impose attribution penalties under default frameworks. Yet we know this to be false, since victim states are increasingly willing to hold host governments liable for the actions of their agents.” (Canfil, 2020, p. 17)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### A government gains plausible deniability based on its centralization strategy.

> “Term Description Range Type φ Extent of outsourcing strategy ∈ [0, 1] G’s Strategy ψ Operational sophistication (probability of success) ∈ [0, 1] Exogenous u ̃ Return on scale of investment ∈ R>0 Exogenous x Campaign investment ∈ R≥0 Exogenous θ Distance between principal / agent ideal points ∈ R≥0 Exogenous γ Fixed cost of centralization ∈ R≥0 Exogenous c Penalty of being caught & attributed ∈ R≥0 Exogenous τ Target’s ability to attribute (technical attrib.) ∈ [0, 1] Exogenous α Target’s willingness to accuse (political attrib.) ∈ R≥0 Exogenous Table 1: Parameter Guide Departing from conventional accounts that tend to conflate different modes of attribution, this model distinguishes between technical attribution, denoted τ, and political attribution, α.” (Canfil, 2020, p. 17)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### A table outlines key terms and parameters related to cyber operations.

> “Attribution τv is simply the probability of detection, determined by the target state’s capabilities. Under the status quo law of state responsibility, even very sophisticated forensic techniques are often of little help to victims in making a case against sponsoring states for the actions of their agents. The target state must be able to show effective command oversight, and the burden of proof is on the target. This is usually not possible through technical means alone, unless the agents operate directly out of host government networks. Conversely, political attribution, αv > 1, is determined by the target state’s tolerance of circumstantial or legally insufficient evidence. In other words, technical attribution reflects a state’s capability, whereas political attribution represents its willingness to act on the basis of nontechnical evidence. The government’s payoff can be modeled as UG(φ) = ψu ̃x(2 − φ) − θφx − γ (1 − φ) − τv c (αv(φ) + x(1 − φ))” (Canfil, 2020, p. 18)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### Attribution probabilities depend on the capabilities and willingness of the target state.

> “In plain terms, G’s expected benefit is given by the balance of participation, u ̃(2 − φ), times the probability the campaign is successful (ψ), and the amount of material investment required (x). If the campaign is successful, G’s investment yields a return of u ̃x. G has a choice whether to outsource (φ > 0) or centralize the campaign (φ = 0). Outsourcing risks agent drift, with departure costs increasing in agent misalignment times the level of investment (θx). Centralization may also involve investment of some fixed downpayment γ . For example, the government might need to purchase buildings, reorganize cyber units, write contracts, or issue uniforms. Finally, G incurs some penalty based on the target’s ability to detect and attribute the source of a campaign. One can think of this penalty as some mixture of reputational, monetary, diplomatic, or other retributive sanctions imposed by the target state and any other states that back it. The government optimizes φ given the parameters.” (Canfil, 2020, p. 18)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### Governments that prefer outsourcing face risks associated with agent drift.

> “As a stricter test of the theory, eliminate any agent drift θ so that non-state hackers are perfectly loyal to their government. Under the latter condition (coupled with the assumption that H ’s skill is equivalent to G’s), default theory predicts that the government would strictly prefer to outsource. If we can identify any variation in φ at all, this suggests principal-agent problems are neither necessary nor sufficient conditions. As we will see, G’s decision hinges on α.” (Canfil, 2020, p. 18)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### Assuming no agent drift implies that governments would prefer outsourcing.

> “For simplicity, assume the return on investment is linearly increasing in average attack scale (u ̃ = 1). Also equalize the θ assumption by also assuming centralization costs are trivial for high-capacity governments (γ ↓ 0), since these types have substantial resources at their disposal.21 Like the model employed by Lindsay [13], this setup allows us to locate the optimal attack scale. Since I regard x as an exogenous parameter – i.e. the level of force required to achieve an effect – rather than a choice, it is safe to treat the probability of success, ψ, as a constant. Set ψ = 1 for the most interesting case. As a final simplification, assume technical attribution is certain whenever G attacks (τ = 1), and that the penalty c is linearly increasing in scale as a function of the cumulative evidence left behind x. This implies a one-to-one increase in the target’s ability to implicate the host state if the host state runs the campaign directly, since in this case “responsibility” can be proven through technical means alone. Set x, c = 1.” (Canfil, 2020, p. 19)

## 2.The Illogic of Plausible Deniability:2.2 A Model of Outsourcing: Model setup

### Simplified assumptions help explore the equilibrium in outsourcing decisions.

> “This set of assumptions simplifies the equation to UG(φ) = x(2 − φ) − c (αv(φ) + x(1 − φ)). In order to constitute an equilibrium where G outsources, the equation must satisfy the Incentive Compatibility Condition (ICC). This implies φ> 1 a which illustrates the general relationship between outsourcing (φ) and the propensity of target states to react on the basis of circumstantial evidence. However, to make the analysis more interesting, relax the assumption that the scale of the campaign is endogenous to the amount of circumstantial evidence left behind. This instead gives us where expected sanctions are the same for any level of operational investment. I study the relationship between political attribution and φ in Theorem 1. Theorem 1. The higher the willingness of target states to hold the host state responsible for activity conducted within the latter’s borders (α), the lower the host state’s incentive to outsource (φ). Proof of Theorem 1. Because this game is decision theoretic with only one move, there is no Nash solution concept. The decisionmaker locates the ideal level of φ via straightforward optimization. The proof is concise enough to show in the body of the paper. With no loss of generality, square the cost term and divide by two to make the objective function continuously differentiable in the choice variable: (αv(φ) + (1 − φ))2, which gives us the transformation ma x UG(φ) = x(2 − φ) − τ (αv(φ) + (1 − φ))2 The first order condition (FOC) must isolate at least one extremum in order to find a critical point at which G will choose to switch between strategies. Differentiate the function with respect to φ: ∂ ∂ φ UG(·) = −(α + 1)(αφ + φ − 1) − x We can then solve for the optimal level of φ by simply setting the derivative equal to zero and rearranging algebraically for φ. This produces: φ∗ = α − x + 1 (α + 1)2 where α ≥ 0 by assumption (1) The second order condition (SOC) confirms that φ∗ is indeed a global maximum: ∂2 ∂ 2φ UG(φ) = −a2 − 2a − 1 which is < 0 (2) We observe from Equation 2 that the slope is decreasing at U ′′ G , proving that φ∗ maximizes G’s payoff function.” (Canfil, 2020, p. 20)

## 2.The Illogic of Plausible Deniability:A Model of Outsourcing: Analysis

### Outsourcing utility analysis reveals dependency on political blame.

> “We wish to know how UG(φ∗) changes with α, x. Substituting φ∗ into the original equation find calculate G’s expected utility, we obtain UG(φ∗) = x  2− α−x+1 (α + 1)2  −x  α α− x +1 (α + 1)2  +  1− α−x+1 (α + 1)2  which is equivalent to UG(φ∗) = αx2 + αx + x α2 + 2α + 1 (3) Equation 1 models the optimal degree of outsourcing for any level of political blame or attack scale, assuming the best case scenario for all other parameters. Equation 3 models the utility G can expect to receive by adopting the optimal strategy. Although it is clear that outsourcing depends on the relationship between α and x, neither Equation 1nor Equation 3 is immediately intuitive. The relationship becomes more apparent when α is φ∗ is plotted. Figure 2 (right) Figure 2: Optimal level of outsourcing (left) and utility gained from outsourcing (right) given the victim’s propensity to politically attribute sponsors. As victims become more willing and able to attribute, attackers who outsource to proxies face steeper costs. If the victim is prone to responding regardless of whether the attacker denies being involved, then proxies lose their “plausible deniability” appeal. In such a scenario, attackers can only lose from using proxies due to agent drift, and are better off conducting their own in-house operations (when able). shows the utility gained for different levels of φ. Outsourcing becomes less advantageous as α increases. In this model, the target state’s α is common knowledge, so the host state can calibrate its outsourcing behavior accordingly. The plot on the left hand side of Figure 2 maps the expected utility of optimal φ∗. As α increases, the expected gains of centralization (φ∗ ↓) begin to exceed the gains from outsourcing (φ∗ ↑). The only other way the host state can minimize costs is by reducing attack scale. Though the goal of this model is not to treat scale as a choice variable, some operations may require attacks of a scale that are cost-prohibitive given τ × α, consistent with Lindsay [13]’s findings on deterrence. Imputing values can help give us more precise point estimates.” (Canfil, 2020, p. 22)

## 2.The Illogic of Plausible Deniability:A Model of Outsourcing: Analysis

### Outsourcing decisions are influenced by the target state's willingness to attribute blame.

> “Example 1. Suppose the target state upholds a strict interpretation of the law on state responsibility, such that it is reluctant to assign blame on the basis of any nontechnical evidence (α = 0). Then the optimal level of outsourcing is φ∗ = x and G would receive UG(φ∗) = u ̃x for any level of x. The value of x that maximizes this relationship is 1, so φ∗ = 1. In other words, G gains plausible deniability for outsourcing and (absent any agent drift and assuming equal probability of success) the host stands to gain from outsourcing everything. It also implies (under identical conditions and assuming u ̃ > 1) that G would adopt a totally permissive attitude toward its hacker pool, since more activity yields a strictly better payoff. This outcome captures the conventional wisdom. Example 2. How can we explain decisions not to outsource? Suppose a high willingness on the part of the target to politically attribute, e.g. α = 10. Then φ∗ = (10x2 + 11x)/121, and the calculation becomes more complex.22 Fixing φ∗ = 0.148, x∗ = 0.895 at their optima (see previous footnote), G can expect to receive 0.148u ̃. Note that G’s maximum payoff is strictly (and significantly) lower when α = 1 no matter what its strategy. Payoffs diminish further as α increases or return on investment u ̃ decreases, even when agents are perfectly loyal and highly capable, until rising penalties discourage the host government from outsourcing at all.” (Canfil, 2020, p. 22)

## 2.The Illogic of Plausible Deniability:A Model of Outsourcing: Discussion

### The potential for political blame reduces the attractiveness of outsourcing in cyber operations.

> “In nontechnical terms, the conditions under which it pays more to outsource than to centralize are narrowed by target states’ increased willingness to assign political blame on the basis of technically insufficient or legally inadmissible evidence. Detection plus suspicions may sometimes be enough. The knowledge that one could be held accountable, whether publicly or privately, removes the incentives to outsource, especially when proxies are unsophisticated, careless, inefficient, lack fidelity to the cause, or have their own ulterior agenda. Even when proxies are perfect efficient and reliable, political attribution can dampen the attractiveness of outsourcing strategies.” (Canfil, 2020, p. 23)

## 2.The Illogic of Plausible Deniability:A Model of Outsourcing: Discussion

### States increasingly prefer centralized cyber strategies over outsourcing due to improved political accountability.

> “In practice, the choice to outsource or centralize is not binary. States are free to pursue both strategies, with the understanding that resources must be divided. The model shows, however, that unless political attribution differs strongly between various operational applications, states are on average better off adopting the latter strategy. Empirical observations support these predictions, albeit only indirectly. The US government is both increasingly willing to indict host states for their connection to proxies, and increasingly capable of providing technical evidence to substantiate its accusations. Similarly, punishments may be more regularized under the US’ new policy of persistent engagement, and more states now see an interest in fostering robust, centrally operated cyber institutions [55] as opposed to decentralized strategies, such as outsourcing.” (Canfil, 2020, p. 24)

## 3. Empirical Strategy

### Outsourcing cyber strategies may be less viable due to accountability concerns.

> “Researchers may not be able to test whether outsourcing is on the rise or decline directly, but they can ask about insourcing, since the latter is by definition more observable. We can also test whether known victim responses are associated with these changes. In this section, I provide evidence that they are. Limitations in the data notwithstanding, the findings lend support to the proposition that outsourcing may no longer pay because victims are increasingly willing to implicate states they suspect of being involved, even in the absence of smoking gun evidence. If true, it suggests a notable change is underway: if sponsors worry they will be held accountable regardless, then why not avoid the Promethean dilemmas associated with proxies?” (Canfil, 2020, p. 24)

## 3. Empirical Strategy

### No dataset currently exists to track declines in proxy relationships.

> “There is no dataset that tracks negative variation in proxy relationships over time. As mentioned, EVIDENCE VALUE SUSPICIOUS TARGET Uniformed Personnel (5) Direct proof Implausibly deniable Agency/Contractor (4) Strong proof Implausibly deniable IoCs: Known Group (3) Technical proof Questionably deniable IoCs: Location (2) Technical proof Plausibly deniable Cui bono (1) Circumstantial proof Plausibly deniable No evidence (0) No proof Plausibly deniable Table 2: Quality of evidence cited in attribution for publicly known incidents in CFR dataset, indexed on a {0 : 5} scale. Higher values indicate more obvious sponsor involvement. The last column indicates the theorized level of political cover a sponsor obtains for the operation vis-a-vis a suspicious target state. Bolded values are dichotomized for Models 1 and 2 to differentiate physical evidence (about a person/agency behind the computer) from technical evidence (about the computer system alone).” (Canfil, 2020, p. 24)

## 3. Empirical Strategy

### Proxy relationships cannot be effectively tracked with current datasets.

> “Akoto [33] tracks onset of known proxy relationships only, not termination, and so cannot be used to test for a decline. I opt for the most up-to-date register of state-implicated cyber incidents, the CFR dataset (2005-2021). Incidents in the CFR data are ordered by the date news of an incident broke. I expand the data to include a row for every country (alleged sponsor) per day over this sixteen year period.” (Canfil, 2020, p. 25)

## 3. Empirical Strategy

### CFR dataset provides a comprehensive record of state-implicated cyber incidents.

> “Each observation in CFR’s dataset references two sources. I visited every source to code incidents by the level of evidence used to establish that a particular state was involved. In cases where the link did not specify, I investigated further. This generated an index ranging from zero to five, where five was direct evidence that particular government personnel were behind the attack. In cases where no evidence at all for the relationship was provided, I coded this as a 0 (no evidence). See Table 2 for a breakdown of the coding scheme.23 While this approach is far from perfect, the idea is that deniability is more objectively plausible at lower levels of the index (0-2), moderate when IoCs are good (3), and implausible when evidence directly implicates the state (4-5).” (Canfil, 2020, p. 25)

## 3. Empirical Strategy

### CFR dataset incidents are categorized by evidence levels of state involvement.

> “For information on victim responses, I rely on Hinck and Maurer [99]’s data on US indictments of foreign cyber actors. The first state-sponsored indictment was in 2014, nine years after the first CFR-recorded cyber incident. I bring the Hinck and Maurer [99] dataset up to date (2022) by searching the DOJ’s website for news and press releases under the category of cyber crime.24” (Canfil, 2020, p. 26)

## 3. Empirical Strategy

### Victim responses to cyber incidents are tracked through US indictments.

> “Unsealed criminal indictments are a good test of the theory because they are necessarily public. Victims can respond in a variety of ways, from naming and shaming to launching a military counteroffensive [100]. Focusing on US DOJ indictments per se is a sensible approach. The high-profile nature of many of these indictments ensures that the attacking state received the message. The US in particular is also one of the biggest targets of state-sponsored cyberattacks and has been especially active in indicting foreign suspects since 2014 [101]. Besides criminal indictments, the data also include information on whether suspects were extradited and tried, whether sanctions were levied, and, in rare known cases, whether the US hacked back. To code responses, each observation begins with a value of 1 by virtue of there having been a public acknowledgment. The value is increased by increments of 1 for each time the information indicates an additional step.25 This generates a daily count variable ranging from 1 to 4.26” (Canfil, 2020, p. 26)

## 3. Empirical Strategy

### Criminal indictments are a measurable response from victims to cyber attacks.

> “The data are then merged at the country-day level. Events are exceedingly rare given paucity of incidents relative to the total number of country-days between 2005-2021. This level of granularity is computationally challenging to analyze. I therefore consolidate the data at an annual level with no expected loss in generality.” (Canfil, 2020, p. 26)

## 3. Empirical Strategy

### Data on state involvement in cyber incidents indicates increasing direct attribution.

> “In Figure 3, we can see how insourcing has changed over time. Lighter colors indicate more direct evidence that state personnel, rather than non-state proxies, were involved (index values: 4-5). The second category, technical indicators, encompasses technical indicators like network traces and IoCs (index values: 2-3). These technical indicators can be contrasted to the third category, unconfirmed suspicions (index values: 0-1). Incidents with index values of 4 and especially 5 are of particular interest because, as opposed to proxy operations, government involvement is categorically undeniable no matter how strict the burden of proof is set. While a Figure 3: Type of evidence used in support of attributions. The density plot is filled to control for variation in the number of detected operations per year. Lighter shades indicate stronger evidence that a government was involved. Evidence that directly implicates a government culprit (ie. undeniable involvement) is increasing in share over time. greater share of technical evidence has been offered since 2013, direct evidence has become by far the most common form of proof.27 Footnoted caveats notwithstanding, this should imply that states are conducting more operations with their own uniformed personnel. This relationship holds for each of the “big four” US adversaries.” (Canfil, 2020, p. 27)

## Empirical Strategy: Analysis

### The empirical models aim to analyze US responses regarding outsourcing and insourcing.

> “To explain the patterns in Figure 3, we want empirical models that can provide answers to two questions. First, do US responses contribute to more outsurcing (as sponsors seek more plausible deniability) or more insourcing (because deniability isn’t actually plausible)? Second, just how much deniability do proxies afford, anyway? In other words, does the US only respond when it can present direct evidence that a sponsoring state was involved? I estimate two pairs of lagged fixed effects models designed to address these questions.” (Canfil, 2020, p. 28)

## Empirical Strategy: Analysis

### Test results indicate US responses influence adversaries' decisions to insource operations.

> “In the first pair, I test whether US responses are associated with a change in future adversary behavior. In the second pair, I test the reverse: whether evidence of direct state involvement is any more likely to provoke a subsequent US response. Together, these tests tell a compelling story. If the US is just as likely to exact punishment regardless of whether its adversaries rely on proxies, then the use of proxies for plausible deniability no longer pays, and adversaries should insource more going forward. This is consistent with the findings.” (Canfil, 2020, p. 28)

## Empirical Strategy: Analysis

### Assumptions around insourcing and outsourcing in cyber operations impact data measurement.

> “For tractability, I make a necessary assumption. As discussed, it is not possible to measure outsourcing per se because the more plausibly deniable operations are, the more likely they are to drop out of our datasets by pooling with non-state sponsored operations. I assume that aggressors have a consistently high demand for cyber operations in each period, which they can achieve either by insourcing or outsourcing (country/year fixed effects also help account for this unobserved variation, as discussed within). We cannot study outsourcing directly, but as long as this assumption holds, more insourcing should imply less outsourcing.” (Canfil, 2020, p. 28)

## Empirical Strategy: Analysis

### The evidence index is dichotomized to evaluate direct versus indirect involvement in cyber incidents.

> “Next, in order to construct the dependent variable for the first set of models (and independent variable in the second set of models), I dichotomize the evidence index. Evidentiary index values between 4 and 5 are coded as proof that country i was implicated in year j . In order to give plausible deniability maximal benefit of the doubt, values below this threshold, including strong IoCs, are coded as no proof having been observed. This distinguishes between direct involvement (undeniable) and indirect involvement (potentially plausibly deniable). It also ensures we are measuring insourcing per se, and not simply an accumulation of indirect, lower-level evidence. Without a clear way to quantify the scale or severity of a response, the other variable, US response, is also dichotomized for each country-year.” (Canfil, 2020, p. 29)

## Empirical Strategy: Analysis

### Lagged variables are incorporated to clarify the sequence of US responses and subsequent insourcing.

> “I include one-year lags for each variable, Public Response and Observe Insourcing, when used as predictors. This ensures our estimation of the direction of the relationship in each model is one-way and sequential. It allows adversaries time to learn and adjust after the US responds (Models 1-2) and time enough for the US to detect and marshal a public response to adversary intrusions (Models 3-4). Fixed effects are also used to control for any unobserved variation in the predictors that is specific to a sponsoring country or year. Controls are included for the number of incidents that occurred and the year in which they occurred (in the one-way fixed effects models). Without a theoretical basis for adding further controls, I opt for parsimony. Dependent variables: Observe Insourcing → Public Response Sponsor FE Two-Way FE Sponsor FE Two-Way FE (1) (2) (3) (4) Public Response (t − 1) 0.049∗∗∗ (0.016) 0.050∗∗∗ (0.017) Obs. Insourcing (t − 1) 0.028 (0.043) 0.035 (0.042) Year (Control) 0.015∗∗∗ (0.005) 0.013∗∗ (0.006) Incident (Control) 0.114∗∗∗ (0.015) 0.112∗∗∗ (0.010) 0.088∗∗∗ (0.022) 0.082∗∗∗ (0.021) Observations 186 186 186 186 R2 0.450 0.304 0.355 0.207 Adjusted R2 0.409 0.180 0.307 0.065 Note: ∗p<0.1; ∗∗p<0.05; ∗∗∗p<0.01 Table 3: Linear fixed effects models. Results from four specifications with cluster-robust standard errors reported. Estimands of interest are highlighted. The first two models estimate the effect of US responses on other countries’ propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. Even columns present country fixed effects with a time control. Two-way fixed effects are presented in the odd columns.”Table 3 presents the results from all four models. The base models (even columns) use one-way (sponsoring country) fixed effects with a time control. Two-way (country/year) fixed effects are presented in the odd columns as a robustness check.28 Consistent with best practices in the literature, robust standard errors, clustered at the country level, are reported. The first two models estimate the effect of US responses on other countries’ propensity to insource operations in the next period. The latter two examine how direct evidence about who an attacker was in that period contributes to the US government’s willingness to respond publicly in the following period. The estimands in all four models are highlighted.” (Canfil, 2020, p. 29)

## Empirical Strategy: Analysis

### Model 1 demonstrates a significant relationship between US responses and increased insourcing rates.

> “First examine Model 1, the effect of US responses (with a one-year lag) on insourcing. The dependent variable, Observe Insourcing, is whether publicly disclosed incidents in a given year were known to have been conducted directly by another state’s own agencies or uniformed personnel. Model 1 shows that US responses in past periods (t − 1) are positively associated with decisions by other countries to insource in subsequent periods ( p < 0.01).29 Since the dependent variable ranges between 0 and 1, one way to interpret the coefficients is that public responses are associated with a five percent increased likelihood that an adversary will instead rely on its own operatives in future periods.30 Model 2 shows that this finding is robust to two-way fixed effects. Returning to the assumption, if we believe that the demand for cyber operations is inelastic, then an increase in insourcing would imply a decrease in outsourcing.” (Canfil, 2020, p. 30)

## Empirical Strategy: Analysis

### Models 3 and 4 explore how the US reacts based on the strength of the evidence against a sponsor.

> “Models 3 and 4 test the second question: at what evidentiary threshold is the US willing to cast blame? The independent and dependent variables (Observe Insourcing and Public Response, respectively) are on the same scale, but this time Insourcing is lagged by one year. We see that there is no significant association between the US having obtained irrefutable evidence of a sponsor’s involvement and its willingness to respond publicly ( p = 0.35). The US may be able to more accurately detect and attribute systems, but its ability to implicate individuals is apparently unrelated how eagerly it retaliates against the usual suspects.” (Canfil, 2020, p. 31)

## Empirical Strategy: Analysis

### Other factors for insourcing may exist, but they do not invalidate the findings on plausible deniability.

> “Why might states outsource, if not plausible deniability? There are other potential reasons why states might decide to insource more in later years, but these would not upset the findings. For example, target hardening or choice of target might necessitate more sophisticated operations. Hacker collectives in certain countries may no longer be reliably sympathetic. States may want to use new capabilities they have gained. But even if there are additional reasons why states insource, by doing so, plausible deniability is compromised.” (Canfil, 2020, p. 31)

## Empirical Strategy: Analysis

### The inclusion of fixed effects enhances the confidence in the association between US responses and insourcing.

> “Moreover, the inclusion of fixed effects (in Models 1 and 2) should increase our confidence that the US response has strongly contributed to this trend. This approach ensures that any unobserved factors unique to a sponsor or time period are isolated and eliminated when they might affect the outcome. The same is true for Models 3 and 4, which estimate how the US responds to different countries over time depending on the evidence. Because other possible factors are accounted for by fixed effects, it “reduces concerns that omitted variables drive any associations between dependent and independent variable” [104].” (Canfil, 2020, p. 31)

## Empirical Strategy: Analysis

### Tentative results suggest a shift from outsourcing to insourcing among state actors in cyber operations.

> “Though caution should be used in interpreting these results given limitations in the data and secrecy in cyberspace more generally, they offer tentative support for the theory that proxies may no longer pay. The US is far from the only cyber victim, but it is among the most vocal [105]. The US now seems to be realizing that complicity is in the eye of the beholder. US adversaries surely perceive this change. If interest in completing operational objectives through cyber has been consistent since 2014, more insourcing would imply less outsourcing. This is unfortunately untestable. However, as long as this condition holds, the empirical results would seem to confirm that sponsors are adjusting their behavior by outsourcing less and insourcing more.” (Canfil, 2020, p. 31)

## Conclusion

### New cyber norms may be emerging regarding state responsibility for cyberattacks.

> “Scholars have long been interested in the conditions under which new cyber norms can emerge and proliferate [106–109]. Naval privateering was once common; states used letters of marque to commission pirates and mercenaries to conduct raids on their adversaries, but this strategy became obsolete in part because victims changed the norm by holding state sponsors responsible [110, 111]. Could new norms around state responsibility for cyberattacks also be coalescing around lower evidentiary barriers? This paper cannot, and does not, definitively contend that outsourcing is in fact on the decline. Instead, it is intended to caution against overreliance on untested assumptions about what states are doing and why they do it.” (Canfil, 2020, p. 32)

## Conclusion

### Outsourcing trends in cyberspace are uncertain due to varying evidentiary interpretations.

> “On the open source level, it is impossible to say with certainty whether outsourcing is increasing, decreasing, or staying the same. Outsourcing could be declining because deniability no longer plausible. But if proxies really do still convey deniability, and this deniability is plausible, then the patterns in Figure 2 make sense: operations would be impossible to connect to a sponsoring government, so observers would (mistakenly) perceive no increase in outsourcing trends. In short, observed patterns are produced by one of two mutually exclusive data-generating processes: a true decline, or a turn away from ineffective proxies in favor of even stealthier alternatives.” (Canfil, 2020, p. 32)

## Conclusion

### Careful analysis is needed before accepting the 'plausible deniability' presumption.

> “This potential for observational equivalence is all the more reason why we should be cautious before uncritically adopting the “plausible deniability” assumption. Embracing multiple possibilities can help us understand the sensitivity of our theories to our underlying assumptions. Moreover, the statistical model presents at least some empirical support for the idea that the plausible deniability conjecture is misplaced, and that outsourcing might no longer pay. Trying to measure outsourcing directly is problematic for reasons discussed above. A more tractable approach is to measure the relative propensity of attackers to conduct their own operations. The more involved the sponsoring government is, the more likely the operation is to show up in data on state-linked attacks. This is because the leap between attack detection and political attribution is easier to make. Where conduct is known to be direct, involvement in detected attacks is objectively undeniable. If proxies are at best substitutable for government operations, but governments are observed to be doing more on their own, then this could imply a decline in outsourcing.” (Canfil, 2020, p. 32)

## Conclusion

### Data shows that state attackers are increasingly conducting their operations directly.

> “As opposed to data on outsourcing, the data on insourcing – which we can test – do seem to tell a compelling story. Attackers are conducting a greater proportion of attacks themselves. We can also test whether this change has anything to do with implausible deniability. The results indicate that public responses by powerful victims like the US are statistically predictive of more direct operational involvement by government operatives in subsequent attacks. Moreover, since 2014, the quality of evidence regarding state involvement seems to have no predictive value in whether victims respond. Attribution may be getting more sophisticated, but victims’ suspicions are basis enough. In either case, attackers lose their political cover from outsourcing.31” (Canfil, 2020, p. 33)

## Conclusion

### Lack of plausible deniability may deter state sponsors from outsourcing operations.

> “Without plausible deniability, would-be sponsors face a variety of disincentives. In conventional spaces, some speculate that outsourcing generally leads to wider disruption and collateral damage [20], whereas state control minimizes these byproducts [112]. In the cyber context, host states may not wish to risk bringing neutral parties into the fray, accidentally damaging assets in blue space, or violating emerging norms of international humanitarian law, such as the prohibition on attacking critical infrastructure in peacetime. Mounting evidence has also led some researchers and policymakers to cautiously conclude that cyber conflict is not inherently escalatory, anyway [56, 58]. If true, why jeopardize operational efficiency by outsourcing to outside actors who might be less-than-reliable? In converse, command centralization may come with advantages in terms of the division of skilled labor, economies of scale, and operational coherence.” (Canfil, 2020, p. 33)

## Conclusion

### Outsourcing may serve purposes beyond plausible deniability, including nationalistic signaling.

> “If not plausible deniability, then why outsource? It is possible that outsourcing is not always designed to affect a target but rather to rally nationalism for internal cohesion [73, 113, 114] or external signaling purposes [26, 115]. And at times and in places where online nationalism is elevated [see e.g. 25], host states should find it easier than ever to co-opt sympathetic hackers. When non-state proxies are ideologically aligned with the state’s objectives [93], or when the host state lacks capacity to conduct covert operations of its own [20, 116], a state can preserve its own resources by outsourcing to them. In some rare cases, proxies might even be more sophisticated than the state and therefore able to accomplish things the state cannot. State support can also transform a group’s goals [117], helping not only to minimize agency drift but to stem it [cf. 8]. However, if states are using proxies for reasons other than plausible deniability, then this would be reflected in the data by an increasing trend. This is not what the data in Figure 2 depict.” (Canfil, 2020, p. 34)

## Conclusion

### theoretic models enhance understanding of unreliable data in cyber conflict.

> “Formalizations such as the decision-theoretic model used in this paper offers several advantages to the study of cyber conflict in areas where measurement, selection, and reporting bias are presumed to be especially severe. Herr, Laudrain, and Smeets [118], Gorwa and Smeets [119], and others have issued a call to action to cyber researchers to pay greater attention to the internal validity of their theories. Theories should be expected to generate clean and testable empirical predictions if the science of cyber conflict is to advance [119]. Formal models like the one employed in this paper, while underutilized, are uniquely suited for studying relationships in which data are unreliable or elusive. Formalization allows researchers to demonstrate exactly why some explanations can be safely ruled out and others cannot. They can also help isolate a set of valid hypotheses, assess the relative importance of certain variables, and generate falsifiable predictions for when better data do become available.” (Canfil, 2020, p. 34)

## Conclusion

### Cyber conflict scholarship is poised for an empirical shift toward quantitative studies.

> “Cyber conflict scholarship is on the cusp of a more empirical turn. In addition to the rich body of qualitative work already prevalent in cyber conflict studies, quantitative and large-n studies can provide special insight into broader patterns [eg. 54, 56]. Moving forward, tools that ensure that the theoretical predictions underpinning empirical studies are clear, parsimonious, and internally consistent will be especially valuable, regardless of methodological orientation.” (Canfil, 2020, p. 34)

